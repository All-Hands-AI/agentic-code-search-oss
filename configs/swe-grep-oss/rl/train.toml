max_steps = 5

[model]
name = "willcb/Qwen3-8B"

[model.ac]
freq = 1  # Full gradient checkpointing (every layer)

[model.experimental.lora]
rank = 4
alpha = 8
dropout = 0.0
target_modules = [
    "q_proj",
    "k_proj",
    "v_proj",
    "o_proj",
    "gate_proj",
    "up_proj",
    "down_proj"
]

[optim]
lr = 1e-5
weight_decay = 0.0

