{"instance_id": "astropy__astropy-12907", "error": "Conversation run failed for id=74f9d5e1-61d8-43f2-8bb5-77233df85cb2: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=Qwen/Qwen3-8B\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "precision": 0.0, "recall": 0.0, "f1": 0.0}
{"instance_id": "astropy__astropy-14182", "error": "Conversation run failed for id=f4cb7c16-1653-40b6-aaf0-7e446dfa09fa: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=Qwen/Qwen3-8B\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "precision": 0.0, "recall": 0.0, "f1": 0.0}
{"instance_id": "astropy__astropy-14365", "error": "Conversation run failed for id=9d14a8d0-e700-4d26-90bf-a564719cdc41: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=Qwen/Qwen3-8B\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "precision": 0.0, "recall": 0.0, "f1": 0.0}
{"instance_id": "astropy__astropy-14995", "error": "Conversation run failed for id=4e01b82e-90fb-40be-89fe-8f32ab4818d6: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=Qwen/Qwen3-8B\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "precision": 0.0, "recall": 0.0, "f1": 0.0}
{"instance_id": "astropy__astropy-6938", "error": "Conversation run failed for id=c680560b-4417-4cfc-ba32-a14d8d01fd5b: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=Qwen/Qwen3-8B\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers", "precision": 0.0, "recall": 0.0, "f1": 0.0}
